# -*- coding: utf-8 -*-
"""ClasificadorFunciones.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q5tYfFSVYf5yRe4pTrnECB-6GfRUgHQS
"""

# -*- coding: utf-8 -*-
"""
Created on Sat Apr 24 12:57:22 2021

@author: joelv
"""
import matplotlib.pyplot as plt
import numpy as np
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer

# función para visualizar gráficamente la evolución del entrenamiento
def plot_history(history, validation=False):
  plt.figure(0)  
  plt.plot(history.history['ID_acc'],'b')    
  plt.plot(history.history['RM_acc'],'r')  
  plt.plot(history.history['CC_acc'],'g')  
  plt.plot(history.history['val_ID_acc'],'c')
  plt.plot(history.history['val_RM_acc'],'m')
  plt.plot(history.history['val_CC_acc'],'y') 
  plt.rcParams['figure.figsize'] = (12, 8)  
  plt.xlabel("Num of Epochs")  
  plt.ylabel("Accuracy")  
  plt.title("Training Accuracy vs Validation Accuracy")  
  plt.legend(['train ID','train RM','train CC','validation ID', 'validation RM', 'validation CC'])

  plt.figure(1)  
  plt.plot(history.history['ID_loss'],'b')  
  plt.plot(history.history['RM_loss'],'r')  
  plt.plot(history.history['CC_loss'],'g')  
  plt.plot(history.history['val_ID_loss'],'c')  
  plt.plot(history.history['val_RM_loss'],'m') 
  plt.plot(history.history['val_CC_loss'],'y') 
  plt.rcParams['figure.figsize'] = (12, 8)  
  plt.xlabel("Num of Epochs")  
  plt.ylabel("Loss")  
  plt.title("Training Loss vs Validation Loss")  
  plt.legend(['train ID','train RM','train CC','validation ID', 'validation RM', 'validation CC'])

  plt.show() 

#funcion para normalizar datos
def NormalizeData(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

#funcion para preprocesar datos
def preprocesador(data, flg_stemm=False, flg_lemm=True, flg_stopwords=True):
  lemmatizer = WordNetLemmatizer()
  stop_words = set(stopwords.words('spanish'))
  
  for i in range(len(data)):
   #separar en tokens. Cada cadena se convierte en una lista de cadenas
   tokens = word_tokenize(data[i])
   
   #quedarse con los tokens solo con letras y pasarlas a minúsculas
   palabras=[word.lower() for word in tokens if word.isalpha()]
   
   #filtrar las stop words
   if flg_stopwords == True:
    palabras = [w for w in palabras if not w in stop_words]
    
   #stemming, cada palabra se reemplaza por su raíz
   if flg_stemm == True:
    ps = PorterStemmer()
    palabras=[ps.stem(w) for w in palabras]
   
   #lemmatización, cada palabra se reemplaza por la palabra de su familia
   #más representativa
   if flg_lemm == True:
    palabras=[lemmatizer.lemmatize(w) for w in palabras]
   
   #se construye una cadena de caracteres con las palabras procesadas
   data[i]=' '.join(palabras)
  return data


#Transforma la palabra dada en su representacion del embedding
def Vectorizar(palabras,model):
  retorno=[]
  for palabra in palabras: retorno += list(map(float,[*model.wv.get_vector(palabra)]))
  return retorno

#Devuelve el porcentaje de acirto para el parametro solicitado: 0-ID, 1-RM y 2-CC
def acierto(numero, clasificacionPredicha, y_test):
  y_pred = np.argmax(clasificacionPredicha[numero], axis=1)+1
  accuracy_red = sum(y_pred == np.argmax(y_test[:,numero], axis=1)+1) / y_pred.size * 100
  return accuracy_red
  
#Devuelve la matriz de confusion para los valores enviados y el parametro indicado
def matriz_confusion(parametro, y_test, clasificacionPredicha):
  snn_predicted = np.argmax(clasificacionPredicha[parametro], axis=1)+1 

  import seaborn as sn 
  from sklearn.metrics import classification_report, confusion_matrix
  #Creamos la matriz de confusión
  snn_cm = confusion_matrix(np.argmax(y_test[:,parametro], axis=1)+1, snn_predicted)

  # Visualizamos la matriz de confusión
  import pandas as pd
  snn_df_cm = pd.DataFrame(snn_cm, range(1,6), range(1,6))  
  plt.figure(figsize = (10,7))  
  sn.set(font_scale=1.4) #for label size  
  sn.heatmap(snn_df_cm, annot=True, annot_kws={"size": 12}) # font size  
  plt.ylabel("Valor real")  
  plt.xlabel("Valor predicho")  
  plt.show()  

  snn_report = classification_report(np.argmax(y_test[:,parametro], axis=1)+1, snn_predicted)  
  print(snn_report)
  
def porcentajeANota(lista):
  prediccion=np.zeros(len(lista))
  for i in range(len(lista)):
    numero=0
    for j in range(len(lista[i])):
      numero += lista[i][j]*(j+1)
    prediccion[i] = numero
  return prediccion